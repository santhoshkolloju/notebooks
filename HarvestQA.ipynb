{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HarvestQA.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"eQgZo65aqt01","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"4aa08b8d-dc69-4a7f-bb24-34976d0e6c60","executionInfo":{"status":"ok","timestamp":1573387278196,"user_tz":-330,"elapsed":104820,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}}},"source":["!echo '{\"username\":\"santhoshkolloju6693\",\"key\":\"f2a1d402f1c35e8a0e74d6373eeec602\"}' > ~/.kaggle/kaggle.json\n","!kaggle competitions download -c tensorflow2-question-answering"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n","Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n","Downloading simplified-nq-test.jsonl.zip to /content\n","  0% 0.00/4.78M [00:00<?, ?B/s]\n","100% 4.78M/4.78M [00:00<00:00, 79.1MB/s]\n","Downloading sample_submission.csv to /content\n","  0% 0.00/18.2k [00:00<?, ?B/s]\n","100% 18.2k/18.2k [00:00<00:00, 57.8MB/s]\n","Downloading simplified-nq-train.jsonl.zip to /content\n","100% 4.46G/4.46G [01:35<00:00, 40.7MB/s]\n","100% 4.46G/4.46G [01:35<00:00, 50.0MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2C4eQgUWL_xT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"1244f30d-315a-402e-87c6-7095f22572ff","executionInfo":{"status":"ok","timestamp":1573387482116,"user_tz":-330,"elapsed":184987,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}}},"source":["!unzip simplified-nq-train.jsonl.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Archive:  simplified-nq-train.jsonl.zip\n","  inflating: simplified-nq-train.jsonl  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oYJbgWYcuXUn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbRJLVF4uXR-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lztI3GC9uXNC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QV-T1COKMR2p","colab_type":"code","colab":{}},"source":["import json\n","with open(\"simplified-nq-train.jsonl\",\"r\") as f:\n","  data = json.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ED8C1OBNq4uB","colab_type":"code","outputId":"40fd6726-0b01-4cec-9d38-f43f1f62368a","executionInfo":{"status":"ok","timestamp":1573260946425,"user_tz":-330,"elapsed":23321,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VH7D33Q0q5dg","colab_type":"code","colab":{}},"source":["import json\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKbDX82trCzm","colab_type":"code","colab":{}},"source":["with open('/content/drive/My Drive/train.json','r') as f:\n","  squad_train = json.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pIpbYFsrvTW","colab_type":"code","colab":{}},"source":["combine_cq =[]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6glmumgr2e1","colab_type":"code","colab":{}},"source":["for i in range(len(squad_train['data'])):\n","  for j in range(len(squad_train['data'][i]['paragraphs'])):\n","    for k in range(len(squad_train['data'][i]['paragraphs'][j]['qas'])):\n","      combine_cq.append({\n","          \"question\":squad_train['data'][i]['paragraphs'][j]['qas'][k]['question'],\n","          \"context\":squad_train['data'][i]['paragraphs'][j]['context']\n","          \n","          \n","      })\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY6-oM9VsGR5","colab_type":"code","colab":{}},"source":["combine_cq = combine_cq[240000:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Xu1rU84sL7D","colab_type":"code","outputId":"49361ec7-7fe3-4f3d-dacf-02e8f3029351","executionInfo":{"status":"ok","timestamp":1573228022923,"user_tz":-330,"elapsed":1378,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["combine_cq[-1008]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': \"Construction work is carried out on several lines of the new Wuhan Metropolitan Area Intercity Railway, which will eventually connect Wuhan's three main rail terminals with several stations throughout the city's outer areas and farther suburbs, as well as with the nearby cities of Xianning, Huangshi, Huanggang, and Xiaogan. The first line of the system, the one to Xianning, opened for passenger operations at the end of 2013.\",\n"," 'question': \"what is the name of the railway that will connect wuhan 's three main rail terminals ?\"}"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"IImSx6xQsOp7","colab_type":"code","outputId":"7388bbc9-fb0c-450d-da24-0358a270f04e","executionInfo":{"status":"ok","timestamp":1573261089442,"user_tz":-330,"elapsed":70296,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["!git clone https://github.com/martiansideofthemoon/squash-generation.git\n","!cp -r squash-generation/pytorch-pretrained-BERT/pytorch_pretrained_bert .\n","!rm -r train_data eval_data\n","!mkdir train_data\n","!mkdir eval_data\n","for i in range(len(combine_cq)):\n","  file_name = \"train_data/example\"+str(i)+\".txt\"\n","  with open(file_name,'w') as f:\n","    f.write(str(combine_cq[i]['context'].strip().replace(\"|||\",\"\"))+\"|||\"+str(combine_cq[i]['question'].strip()))\n","  f.close()\n","\n","for i in range(100):\n","  file_name = \"eval_data/example\"+str(i)+\".txt\"\n","  with open(file_name,'w') as f:\n","    f.write(str(combine_cq[i]['context'].strip())+\"|||\"+str(combine_cq[i]['question'].strip()))\n","  f.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'squash-generation'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 375 (delta 1), reused 1 (delta 0), pack-reused 369\u001b[K\n","Receiving objects: 100% (375/375), 397.70 KiB | 577.00 KiB/s, done.\n","Resolving deltas: 100% (177/177), done.\n","rm: cannot remove 'train_data': No such file or directory\n","rm: cannot remove 'eval_data': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vTV5Lwdutc3_","colab_type":"code","outputId":"8b505c37-a3d2-4e64-85aa-8a85d5c7cce8","executionInfo":{"status":"ok","timestamp":1573261396982,"user_tz":-330,"elapsed":253369,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install -r squash-generation/requirements.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting absl-py==0.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n","\r\u001b[K     |███▎                            | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20kB 31.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 35.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 40kB 38.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 36.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 61kB 39.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 71kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 81kB 22.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 92kB 23.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n","\u001b[?25hRequirement already satisfied: alabaster==0.7.12 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 2)) (0.7.12)\n","Collecting allennlp==0.8.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/8c/72b14d20c9cbb0306939ea41109fc599302634fd5c59ccba1a659b7d0360/allennlp-0.8.4-py3-none-any.whl (5.7MB)\n","\u001b[K     |████████████████████████████████| 5.7MB 35.1MB/s \n","\u001b[?25hCollecting astor==0.7.1\n","  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n","Requirement already satisfied: atomicwrites==1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 5)) (1.3.0)\n","Collecting attrs==19.1.0\n","  Downloading https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl\n","Collecting awscli==1.16.184\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/f7/4a2ed465345a87d20cb6c3fc6bec33f1a4d18974223b88711300a0ff1d4a/awscli-1.16.184-py2.py3-none-any.whl (1.7MB)\n","\u001b[K     |████████████████████████████████| 1.7MB 56.9MB/s \n","\u001b[?25hRequirement already satisfied: Babel==2.7.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 8)) (2.7.0)\n","Requirement already satisfied: blis==0.2.4 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 9)) (0.2.4)\n","Collecting boto3==1.9.151\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/82/19a624dc95bc9bdd1f3f1e76eb1962539c54cf1d9e533e8f8b310a298593/boto3-1.9.151-py2.py3-none-any.whl (128kB)\n","\u001b[K     |████████████████████████████████| 133kB 76.7MB/s \n","\u001b[?25hCollecting botocore==1.12.174\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/74/fcca5254234a55517d1016d8e0e342a53a642ff3216d156416abeedef3ea/botocore-1.12.174-py2.py3-none-any.whl (5.6MB)\n","\u001b[K     |████████████████████████████████| 5.6MB 26.8MB/s \n","\u001b[?25hCollecting certifi==2019.3.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/75/f692a584e85b7eaba0e03827b3d51f45f571c2e793dd731e598828d380aa/certifi-2019.3.9-py2.py3-none-any.whl (158kB)\n","\u001b[K     |████████████████████████████████| 163kB 59.9MB/s \n","\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 13)) (3.0.4)\n","Requirement already satisfied: Click==7.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 14)) (7.0)\n","Collecting colorama==0.3.9\n","  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n","Collecting conllu==0.11\n","  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 17)) (0.10.0)\n","Requirement already satisfied: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 18)) (2.0.2)\n","Collecting docutils==0.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n","\u001b[K     |████████████████████████████████| 552kB 53.0MB/s \n","\u001b[?25hRequirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 20)) (0.5.3)\n","Collecting flaky==3.5.3\n","  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\n","Collecting Flask==1.0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/74/670ae9737d14114753b8c8fdf2e8bd212a05d3b361ab15b44937dfd40985/Flask-1.0.3-py2.py3-none-any.whl (92kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.3MB/s \n","\u001b[?25hCollecting Flask-Cors==3.0.8\n","  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n","Collecting ftfy==5.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 25)) (0.2.2)\n","Requirement already satisfied: gevent==1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 26)) (1.4.0)\n","Requirement already satisfied: greenlet==0.4.15 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 27)) (0.4.15)\n","Collecting grpcio==1.20.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/9d/8bd5d0e516b196f59f1c4439b424b8d4fa62d492a4b531aae322d2d82a7b/grpcio-1.20.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 47.7MB/s \n","\u001b[?25hCollecting h5py==2.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 64.3MB/s \n","\u001b[?25hRequirement already satisfied: idna==2.8 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 30)) (2.8)\n","Requirement already satisfied: imagesize==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 31)) (1.1.0)\n","Collecting importlib-metadata==0.18\n","  Downloading https://files.pythonhosted.org/packages/bd/23/dce4879ec58acf3959580bfe769926ed8198727250c5e395e6785c764a02/importlib_metadata-0.18-py2.py3-none-any.whl\n","Requirement already satisfied: itsdangerous==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 33)) (1.1.0)\n","Collecting Jinja2==2.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n","\u001b[K     |████████████████████████████████| 133kB 55.2MB/s \n","\u001b[?25hRequirement already satisfied: jmespath==0.9.4 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 35)) (0.9.4)\n","Collecting joblib==0.13.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n","\u001b[K     |████████████████████████████████| 286kB 58.4MB/s \n","\u001b[?25hCollecting jsonnet==0.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/a8/adba6cd0f84ee6ab064e7f70cd03a2836cefd2e063fd565180ec13beae93/jsonnet-0.13.0.tar.gz (255kB)\n","\u001b[K     |████████████████████████████████| 256kB 63.6MB/s \n","\u001b[?25hCollecting jsonpickle==1.2\n","  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n","Requirement already satisfied: jsonschema==2.6.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 39)) (2.6.0)\n","Collecting Keras-Applications==1.0.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 61kB 11.0MB/s \n","\u001b[?25hCollecting Keras-Preprocessing==1.0.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 42)) (1.1.0)\n","Collecting Markdown==3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/e4/d8c18f2555add57ff21bf25af36d827145896a07607486cc79a2aea641af/Markdown-3.1-py2.py3-none-any.whl (87kB)\n","\u001b[K     |████████████████████████████████| 92kB 14.2MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 44)) (1.1.1)\n","Collecting matplotlib==3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/83/d989ee20c78117c737ab40e0318ea221f1aed4e3f5a40b4f93541b369b93/matplotlib-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n","\u001b[K     |████████████████████████████████| 13.1MB 19.4MB/s \n","\u001b[?25hCollecting mock==3.0.5\n","  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n","Collecting more-itertools==7.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/73/64fb5922b745fc1daee8a2880d907d2a70d9c7bb71eea86fcb9445daab5e/more_itertools-7.0.0-py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n","\u001b[?25hCollecting munch==2.3.2\n","  Downloading https://files.pythonhosted.org/packages/68/f4/260ec98ea840757a0da09e0ed8135333d59b8dfebe9752a365b04857660a/munch-2.3.2.tar.gz\n","Requirement already satisfied: murmurhash==1.0.2 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 49)) (1.0.2)\n","Collecting neuralcoref==4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/24/0ec7845a5b73b637aa691ff4d1b9b48f3a0f3369f4002a59ffd7a7462fdb/neuralcoref-4.0-cp36-cp36m-manylinux1_x86_64.whl (287kB)\n","\u001b[K     |████████████████████████████████| 296kB 36.9MB/s \n","\u001b[?25hCollecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 63.1MB/s \n","\u001b[?25hCollecting numpy==1.16.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/e2/4db8df8f6cddc98e7d7c537245ef2f4e41a1ed17bf0c3177ab3cc6beac7f/numpy-1.16.3-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 237kB/s \n","\u001b[?25hCollecting numpydoc==0.9.1\n","  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n","Collecting overrides==1.9\n","  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n","Collecting packaging==19.0\n","  Downloading https://files.pythonhosted.org/packages/91/32/58bc30e646e55eab8b21abf89e353f59c0cc02c417e42929f4a9546e1b1d/packaging-19.0-py2.py3-none-any.whl\n","Collecting parsimonious==0.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: plac==0.9.6 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 57)) (0.9.6)\n","Collecting pluggy==0.12.0\n","  Downloading https://files.pythonhosted.org/packages/06/ee/de89e0582276e3551df3110088bf20844de2b0e7df2748406876cc78e021/pluggy-0.12.0-py2.py3-none-any.whl\n","Requirement already satisfied: preshed==2.0.1 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 59)) (2.0.1)\n","Collecting protobuf==3.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/aa/a858df367b464f5e9452e1c538aa47754d467023850c00b000287750fa77/protobuf-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 50.2MB/s \n","\u001b[?25hRequirement already satisfied: py==1.8.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 61)) (1.8.0)\n","Collecting pyasn1==0.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/7c/c9386b82a25115cccf1903441bba3cbadcfae7b678a20167347fa8ded34c/pyasn1-0.4.5-py2.py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n","\u001b[?25hCollecting Pygments==2.4.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/73/1dfa428150e3ccb0fa3e68db406e5be48698f2a979ccbcec795f28f44048/Pygments-2.4.2-py2.py3-none-any.whl (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 63.2MB/s \n","\u001b[?25hCollecting pyparsing==2.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n","\u001b[?25hCollecting pyrsistent==0.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/0b/f514e76b4e074386b60cfc6c8c2d75ca615b81e415417ccf3fac80ae0bf6/pyrsistent-0.15.2.tar.gz (106kB)\n","\u001b[K     |████████████████████████████████| 112kB 70.7MB/s \n","\u001b[?25hCollecting pytest==4.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/eb/df264c0b1ff4aaf263375dc09aabd9093364f66060be9b26f3a2c166d558/pytest-4.6.3-py2.py3-none-any.whl (229kB)\n","\u001b[K     |████████████████████████████████| 235kB 64.0MB/s \n","\u001b[?25hCollecting python-dateutil==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n","\u001b[K     |████████████████████████████████| 235kB 73.1MB/s \n","\u001b[?25hCollecting pytorch-ignite==0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/7b/1da69e5fdcb70e8f40ff3955516550207d5f5c81b428a5056510e72c60c5/pytorch_ignite-0.2.0-py2.py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n","\u001b[?25hCollecting pytz==2019.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n","\u001b[K     |████████████████████████████████| 512kB 62.8MB/s \n","\u001b[?25hCollecting PyYAML==5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n","\u001b[K     |████████████████████████████████| 276kB 18.1MB/s \n","\u001b[?25hCollecting regex==2019.4.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/d9/e37129676d508adf833fb3e3c3fbcb4e5a10183cf45b6c7edbaa57b4a1f2/regex-2019.04.14.tar.gz (644kB)\n","\u001b[K     |████████████████████████████████| 645kB 52.4MB/s \n","\u001b[?25hCollecting requests==2.22.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n","\u001b[?25hCollecting responses==0.10.6\n","  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\n","Collecting rsa==3.4.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hCollecting s3transfer==0.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/de/5737f602e22073ecbded7a0c590707085e154e32b68d86545dcc31004c02/s3transfer-0.2.0-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.0MB/s \n","\u001b[?25hCollecting scikit-learn==0.21.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 52.5MB/s \n","\u001b[?25hCollecting scipy==1.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n","\u001b[K     |████████████████████████████████| 25.2MB 52.2MB/s \n","\u001b[?25hRequirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 78)) (1.12.0)\n","Collecting snowballstemmer==1.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/6c/8a935e2c7b54a37714656d753e4187ee0631988184ed50c0cf6476858566/snowballstemmer-1.2.1-py2.py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n","\u001b[?25hCollecting spacy==2.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/da/3a1c54694c2d2f40df82f38a19ae14c6eb24a5a1a0dae87205ebea7a84d8/spacy-2.1.3-cp36-cp36m-manylinux1_x86_64.whl (27.7MB)\n","\u001b[K     |████████████████████████████████| 27.7MB 325kB/s \n","\u001b[?25hCollecting Sphinx==2.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/e5/c9ba68935cd2d72c553d49bc156bfb15ddb40e734ea7e3f238d8bd6ca6f1/Sphinx-2.1.2-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 53.9MB/s \n","\u001b[?25hCollecting sphinxcontrib-applehelp==1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/9a/4428b3114d654cb1cd34d90d5e6fab938d5436f94a571155187ea1dd78b4/sphinxcontrib_applehelp-1.0.1-py2.py3-none-any.whl (121kB)\n","\u001b[K     |████████████████████████████████| 122kB 60.2MB/s \n","\u001b[?25hCollecting sphinxcontrib-devhelp==1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/a3/fea98741f0b2f2902fbf6c35c8e91b22cd0dd13387291e81d457f9a93066/sphinxcontrib_devhelp-1.0.1-py2.py3-none-any.whl (84kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.5MB/s \n","\u001b[?25hCollecting sphinxcontrib-htmlhelp==1.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/35/80a67cc493f4a8a9634ab203a77aaa1b84d79ccb1c02eca72cb084d2c7f7/sphinxcontrib_htmlhelp-1.0.2-py2.py3-none-any.whl (96kB)\n","\u001b[K     |████████████████████████████████| 102kB 14.5MB/s \n","\u001b[?25hCollecting sphinxcontrib-jsmath==1.0.1\n","  Downloading https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n","Collecting sphinxcontrib-qthelp==1.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/5b/4747c3ba98b3a3e21a66faa183d8f79b9ded70e74212a7988d236a6eb78a/sphinxcontrib_qthelp-1.0.2-py2.py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.1MB/s \n","\u001b[?25hCollecting sphinxcontrib-serializinghtml==1.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/b3/3648e48fa5682e61e9839d62de4e23af1795ceb738d68d73bd974257a95c/sphinxcontrib_serializinghtml-1.1.3-py2.py3-none-any.whl (89kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.7MB/s \n","\u001b[?25hRequirement already satisfied: sqlparse==0.3.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 88)) (0.3.0)\n","Collecting srsly==0.0.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/97/47753e3393aa4b18de9f942fac26f18879d1ae950243a556888f389d1398/srsly-0.0.5-cp36-cp36m-manylinux1_x86_64.whl (180kB)\n","\u001b[K     |████████████████████████████████| 184kB 64.2MB/s \n","\u001b[?25hCollecting tensorboard==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 64.3MB/s \n","\u001b[?25hCollecting tensorboardX==1.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 68.1MB/s \n","\u001b[?25hCollecting tensorflow==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n","\u001b[K     |████████████████████████████████| 92.5MB 124kB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 53.9MB/s \n","\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 94)) (1.1.0)\n","Collecting thinc==7.0.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/f1/3df317939a07b2fc81be1a92ac10bf836a1d87b4016346b25f8b63dee321/thinc-7.0.4-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 57.5MB/s \n","\u001b[?25hCollecting torch==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n","\u001b[K     |████████████████████████████████| 676.9MB 27kB/s \n","\u001b[?25hCollecting tqdm==4.32.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/af/685bf3ce889ea191f3b916557f5677cc95a5e87b2fa120d74b5dd6d049d0/tqdm-4.32.1-py2.py3-none-any.whl (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n","\u001b[?25hCollecting Unidecode==1.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 64.9MB/s \n","\u001b[?25hCollecting urllib3==1.25.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/ec/d93dfc69617a028915df914339ef66936ea976ef24fa62940fd86ba0326e/urllib3-1.25.2-py2.py3-none-any.whl (150kB)\n","\u001b[K     |████████████████████████████████| 153kB 72.6MB/s \n","\u001b[?25hCollecting wasabi==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/f4/c1/d76ccdd12c716be79162d934fe7de4ac8a318b9302864716dde940641a79/wasabi-0.2.2-py3-none-any.whl\n","Requirement already satisfied: wcwidth==0.1.7 in /usr/local/lib/python3.6/dist-packages (from -r squash-generation/requirements.txt (line 101)) (0.1.7)\n","Collecting Werkzeug==0.15.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl (327kB)\n","\u001b[K     |████████████████████████████████| 327kB 55.3MB/s \n","\u001b[?25hCollecting word2number==1.1\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Collecting zipp==0.5.1\n","  Downloading https://files.pythonhosted.org/packages/a0/0f/9bf71d438d2e9d5fd0e4569ea4d1a2b6f5a524c234c6d221b494298bb4d1/zipp-0.5.1-py2.py3-none-any.whl\n","Collecting pytorch-pretrained-bert>=0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 58.0MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver==1.1.0->-r squash-generation/requirements.txt (line 42)) (41.4.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1->-r squash-generation/requirements.txt (line 90)) (0.33.6)\n","Building wheels for collected packages: absl-py, jsonnet, munch, nltk, numpydoc, overrides, parsimonious, pyrsistent, PyYAML, regex, word2number\n","  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for absl-py: filename=absl_py-0.7.1-cp36-none-any.whl size=117847 sha256=044d48100036f241981baa180bbd9714b43cc24fcbb588ae68258ec47395b2c6\n","  Stored in directory: /root/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.13.0-cp36-cp36m-linux_x86_64.whl size=3320342 sha256=5f3500c91382062aca6a0f253c34c0b4050a8cf95c3e8f2a80959beeaec79abd\n","  Stored in directory: /root/.cache/pip/wheels/1a/30/ab/ae4a57b1df44fa20a531edb9601b27603da8f5336225691f3f\n","  Building wheel for munch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for munch: filename=munch-2.3.2-py2.py3-none-any.whl size=6614 sha256=0c13b33235f9b616566bd7c3523f2d7e2027046c75c2bc72accff18f3b3c6612\n","  Stored in directory: /root/.cache/pip/wheels/db/bf/bc/06a3e1bfe0ab27d2e720ceb3cff3159398d92644c0cec2c125\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449908 sha256=571f10e3765180aca3f82017479ff8035d9b0861fb7d38658c87454cec1e267f\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for numpydoc: filename=numpydoc-0.9.1-cp36-none-any.whl size=31872 sha256=5382e7e3b574a664df8ad223f0aa9dc9a104a4c729f6556bc69155ea0f40f707\n","  Stored in directory: /root/.cache/pip/wheels/51/30/d1/92a39ba40f21cb70e53f8af96eb98f002a781843c065406500\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-1.9-cp36-none-any.whl size=4214 sha256=7d716d79ff3732e1cd87160dc610e6942426d6d095f258feb552bccd792746a1\n","  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42709 sha256=9ece58d92d67b871749675a5c0cb6ff934c9ec6c45525293e1bb531dcc41ceac\n","  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n","  Building wheel for pyrsistent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyrsistent: filename=pyrsistent-0.15.2-cp36-cp36m-linux_x86_64.whl size=97499 sha256=a820149f2859bf66cb71758b02d64e1cb6084803fa9b2a0bef0a3b4afd451364\n","  Stored in directory: /root/.cache/pip/wheels/6b/b9/15/c8c6a1e095a370e8c3273e65a5c982e5cf355dde16d77502f5\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44075 sha256=a11bb954daa652f054e0155a129fc7daeb6788aa50ebd73950f2a5852809b451\n","  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for regex: filename=regex-2019.4.14-cp36-cp36m-linux_x86_64.whl size=601897 sha256=a5c2a7f333ede1b4aba8c29bc84650dc03a465e0ffd84dc73ba2104e0873c87b\n","  Stored in directory: /root/.cache/pip/wheels/ae/35/86/47caa8baa5e9340dcb02a719f64a7091900e28af7368d35731\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5588 sha256=67f4e3ee2b2b8db7d48db0faf80e5ffe2cec9ee4242db277e19914adad0a722e\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","Successfully built absl-py jsonnet munch nltk numpydoc overrides parsimonious pyrsistent PyYAML regex word2number\n","\u001b[31mERROR: torchvision 0.4.1+cu100 has requirement torch==1.3.0, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pyasn1-modules 0.2.7 has requirement pyasn1<0.5.0,>=0.4.6, but you'll have pyasn1 0.4.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: keras 2.2.5 has requirement keras-applications>=1.0.8, but you'll have keras-applications 1.0.7 which is incompatible.\u001b[0m\n","\u001b[31mERROR: keras 2.2.5 has requirement keras-preprocessing>=1.1.0, but you'll have keras-preprocessing 1.0.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: absl-py, sphinxcontrib-serializinghtml, sphinxcontrib-jsmath, sphinxcontrib-qthelp, pyparsing, packaging, snowballstemmer, sphinxcontrib-devhelp, Jinja2, sphinxcontrib-applehelp, docutils, sphinxcontrib-htmlhelp, certifi, urllib3, requests, Pygments, Sphinx, numpydoc, attrs, zipp, importlib-metadata, pluggy, more-itertools, pytest, python-dateutil, numpy, matplotlib, protobuf, tensorboardX, responses, Unidecode, ftfy, torch, regex, botocore, s3transfer, boto3, tqdm, pytorch-pretrained-bert, h5py, scipy, Werkzeug, Flask, conllu, word2number, Flask-Cors, jsonpickle, flaky, nltk, jsonnet, joblib, scikit-learn, srsly, wasabi, thinc, spacy, PyYAML, colorama, pyasn1, rsa, awscli, pytz, parsimonious, overrides, allennlp, astor, grpcio, Keras-Applications, Keras-Preprocessing, Markdown, mock, munch, neuralcoref, pyrsistent, pytorch-ignite, tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: absl-py 0.8.1\n","    Uninstalling absl-py-0.8.1:\n","      Successfully uninstalled absl-py-0.8.1\n","  Found existing installation: pyparsing 2.4.2\n","    Uninstalling pyparsing-2.4.2:\n","      Successfully uninstalled pyparsing-2.4.2\n","  Found existing installation: packaging 19.2\n","    Uninstalling packaging-19.2:\n","      Successfully uninstalled packaging-19.2\n","  Found existing installation: snowballstemmer 2.0.0\n","    Uninstalling snowballstemmer-2.0.0:\n","      Successfully uninstalled snowballstemmer-2.0.0\n","  Found existing installation: Jinja2 2.10.3\n","    Uninstalling Jinja2-2.10.3:\n","      Successfully uninstalled Jinja2-2.10.3\n","  Found existing installation: docutils 0.15.2\n","    Uninstalling docutils-0.15.2:\n","      Successfully uninstalled docutils-0.15.2\n","  Found existing installation: certifi 2019.9.11\n","    Uninstalling certifi-2019.9.11:\n","      Successfully uninstalled certifi-2019.9.11\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Found existing installation: requests 2.21.0\n","    Uninstalling requests-2.21.0:\n","      Successfully uninstalled requests-2.21.0\n","  Found existing installation: Pygments 2.1.3\n","    Uninstalling Pygments-2.1.3:\n","      Successfully uninstalled Pygments-2.1.3\n","  Found existing installation: Sphinx 1.8.5\n","    Uninstalling Sphinx-1.8.5:\n","      Successfully uninstalled Sphinx-1.8.5\n","  Found existing installation: attrs 19.3.0\n","    Uninstalling attrs-19.3.0:\n","      Successfully uninstalled attrs-19.3.0\n","  Found existing installation: zipp 0.6.0\n","    Uninstalling zipp-0.6.0:\n","      Successfully uninstalled zipp-0.6.0\n","  Found existing installation: importlib-metadata 0.23\n","    Uninstalling importlib-metadata-0.23:\n","      Successfully uninstalled importlib-metadata-0.23\n","  Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Found existing installation: more-itertools 7.2.0\n","    Uninstalling more-itertools-7.2.0:\n","      Successfully uninstalled more-itertools-7.2.0\n","  Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","  Found existing installation: python-dateutil 2.6.1\n","    Uninstalling python-dateutil-2.6.1:\n","      Successfully uninstalled python-dateutil-2.6.1\n","  Found existing installation: numpy 1.17.3\n","    Uninstalling numpy-1.17.3:\n","      Successfully uninstalled numpy-1.17.3\n","  Found existing installation: matplotlib 3.1.1\n","    Uninstalling matplotlib-3.1.1:\n","      Successfully uninstalled matplotlib-3.1.1\n","  Found existing installation: protobuf 3.10.0\n","    Uninstalling protobuf-3.10.0:\n","      Successfully uninstalled protobuf-3.10.0\n","  Found existing installation: torch 1.3.0+cu100\n","    Uninstalling torch-1.3.0+cu100:\n","      Successfully uninstalled torch-1.3.0+cu100\n","  Found existing installation: botocore 1.13.7\n","    Uninstalling botocore-1.13.7:\n","      Successfully uninstalled botocore-1.13.7\n","  Found existing installation: s3transfer 0.2.1\n","    Uninstalling s3transfer-0.2.1:\n","      Successfully uninstalled s3transfer-0.2.1\n","  Found existing installation: boto3 1.10.7\n","    Uninstalling boto3-1.10.7:\n","      Successfully uninstalled boto3-1.10.7\n","  Found existing installation: tqdm 4.28.1\n","    Uninstalling tqdm-4.28.1:\n","      Successfully uninstalled tqdm-4.28.1\n","  Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Found existing installation: scipy 1.3.1\n","    Uninstalling scipy-1.3.1:\n","      Successfully uninstalled scipy-1.3.1\n","  Found existing installation: Werkzeug 0.16.0\n","    Uninstalling Werkzeug-0.16.0:\n","      Successfully uninstalled Werkzeug-0.16.0\n","  Found existing installation: Flask 1.1.1\n","    Uninstalling Flask-1.1.1:\n","      Successfully uninstalled Flask-1.1.1\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: joblib 0.14.0\n","    Uninstalling joblib-0.14.0:\n","      Successfully uninstalled joblib-0.14.0\n","  Found existing installation: scikit-learn 0.21.3\n","    Uninstalling scikit-learn-0.21.3:\n","      Successfully uninstalled scikit-learn-0.21.3\n","  Found existing installation: srsly 0.2.0\n","    Uninstalling srsly-0.2.0:\n","      Successfully uninstalled srsly-0.2.0\n","  Found existing installation: wasabi 0.3.0\n","    Uninstalling wasabi-0.3.0:\n","      Successfully uninstalled wasabi-0.3.0\n","  Found existing installation: thinc 7.0.8\n","    Uninstalling thinc-7.0.8:\n","      Successfully uninstalled thinc-7.0.8\n","  Found existing installation: spacy 2.1.9\n","    Uninstalling spacy-2.1.9:\n","      Successfully uninstalled spacy-2.1.9\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: pyasn1 0.4.7\n","    Uninstalling pyasn1-0.4.7:\n","      Successfully uninstalled pyasn1-0.4.7\n","  Found existing installation: rsa 4.0\n","    Uninstalling rsa-4.0:\n","      Successfully uninstalled rsa-4.0\n","  Found existing installation: pytz 2018.9\n","    Uninstalling pytz-2018.9:\n","      Successfully uninstalled pytz-2018.9\n","  Found existing installation: astor 0.8.0\n","    Uninstalling astor-0.8.0:\n","      Successfully uninstalled astor-0.8.0\n","  Found existing installation: grpcio 1.15.0\n","    Uninstalling grpcio-1.15.0:\n","      Successfully uninstalled grpcio-1.15.0\n","  Found existing installation: Keras-Applications 1.0.8\n","    Uninstalling Keras-Applications-1.0.8:\n","      Successfully uninstalled Keras-Applications-1.0.8\n","  Found existing installation: Keras-Preprocessing 1.1.0\n","    Uninstalling Keras-Preprocessing-1.1.0:\n","      Successfully uninstalled Keras-Preprocessing-1.1.0\n","  Found existing installation: Markdown 3.1.1\n","    Uninstalling Markdown-3.1.1:\n","      Successfully uninstalled Markdown-3.1.1\n","  Found existing installation: pyrsistent 0.15.5\n","    Uninstalling pyrsistent-0.15.5:\n","      Successfully uninstalled pyrsistent-0.15.5\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed Flask-1.0.3 Flask-Cors-3.0.8 Jinja2-2.10.1 Keras-Applications-1.0.7 Keras-Preprocessing-1.0.9 Markdown-3.1 PyYAML-5.1 Pygments-2.4.2 Sphinx-2.1.2 Unidecode-1.1.1 Werkzeug-0.15.4 absl-py-0.7.1 allennlp-0.8.4 astor-0.7.1 attrs-19.1.0 awscli-1.16.184 boto3-1.9.151 botocore-1.12.174 certifi-2019.3.9 colorama-0.3.9 conllu-0.11 docutils-0.14 flaky-3.5.3 ftfy-5.5.1 grpcio-1.20.1 h5py-2.9.0 importlib-metadata-0.18 joblib-0.13.2 jsonnet-0.13.0 jsonpickle-1.2 matplotlib-3.1.0 mock-3.0.5 more-itertools-7.0.0 munch-2.3.2 neuralcoref-4.0 nltk-3.4.5 numpy-1.16.3 numpydoc-0.9.1 overrides-1.9 packaging-19.0 parsimonious-0.8.1 pluggy-0.12.0 protobuf-3.7.1 pyasn1-0.4.5 pyparsing-2.4.0 pyrsistent-0.15.2 pytest-4.6.3 python-dateutil-2.8.0 pytorch-ignite-0.2.0 pytorch-pretrained-bert-0.6.2 pytz-2019.1 regex-2019.4.14 requests-2.22.0 responses-0.10.6 rsa-3.4.2 s3transfer-0.2.0 scikit-learn-0.21.2 scipy-1.3.0 snowballstemmer-1.2.1 spacy-2.1.3 sphinxcontrib-applehelp-1.0.1 sphinxcontrib-devhelp-1.0.1 sphinxcontrib-htmlhelp-1.0.2 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.2 sphinxcontrib-serializinghtml-1.1.3 srsly-0.0.5 tensorboard-1.13.1 tensorboardX-1.6 tensorflow-1.13.1 tensorflow-estimator-1.13.0 thinc-7.0.4 torch-1.1.0 tqdm-4.32.1 urllib3-1.25.2 wasabi-0.2.2 word2number-1.1 zipp-0.5.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","dateutil","google","grpc","matplotlib","mpl_toolkits","numpy","pyasn1","pygments","pyparsing","pytz","requests","rsa","sphinxcontrib","tqdm","urllib3"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7ra4D7zHuqVJ","colab_type":"code","outputId":"3b49f123-aa49-44d6-e916-f7a4e54af7c3","executionInfo":{"status":"ok","timestamp":1573261472096,"user_tz":-330,"elapsed":9723,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import os\n","import math\n","import logging\n","from pprint import pformat\n","from collections import defaultdict\n","from itertools import chain\n","\n","import torch\n","from torch.nn.parallel import DistributedDataParallel\n","from torch.utils.data import DataLoader, TensorDataset\n","from ignite.engine import Engine, Events\n","from ignite.handlers import ModelCheckpoint\n","from ignite.metrics import Accuracy, Loss, MetricsLambda, RunningAverage\n","from ignite.contrib.handlers import ProgressBar, PiecewiseLinear\n","from ignite.contrib.handlers.tensorboard_logger import TensorboardLogger, OutputHandler, OptimizerParamsHandler\n","from pytorch_pretrained_bert import (OpenAIAdam, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer,\n","                                     GPT2LMHeadModel, GPT2Tokenizer, WEIGHTS_NAME, CONFIG_NAME)\n","#from tqdm import tqdm_notebook\n","\n","SPECIAL_TOKENS = [\n","    \"<bos>\", \"<eos>\", \"<context>\",\"<question>\",\"<answer>\",\"<pad>\"\n","]\n","MODEL_INPUTS = [\"input_ids\", \"lm_labels\", \"token_type_ids\"]\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","bos, eos, context,question,answer,pad = \\\n","          tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS)\n","tokenizer.set_special_tokens(SPECIAL_TOKENS)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 1042301/1042301 [00:01<00:00, 690820.76B/s]\n","100%|██████████| 456318/456318 [00:01<00:00, 418264.84B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AnOPcojfuz9y","colab_type":"code","colab":{}},"source":["#answer first \n","\n","from torch.utils.data import Dataset, DataLoader\n","def get_example(txt):\n","  inst = {}\n","  try:\n","    context,question = txt.strip().split(\"|||\")\n","  except:\n","    print(txt)\n","  toks1 = tokenizer.tokenize(context.strip())\n","  toks2 = tokenizer.tokenize(question.strip())\n"," \n","  if (len(toks1) + len(toks2))< 1019:\n","    inst['context'] = tokenizer.convert_tokens_to_ids(toks1)\n","    inst['question'] = tokenizer.convert_tokens_to_ids(toks2)\n","  else:\n","    #count = count+1\n","    max_len_for_article = 1019 - len(toks2)\n","    inst['context'] = tokenizer.convert_tokens_to_ids(toks1)[:max_len_for_article]\n","    inst['question'] = tokenizer.convert_tokens_to_ids(toks2)\n","    \n","  bos, eos, context,question,answer,pad = \\\n","          tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS)\n","  instance = {}\n","  \n","  sequence = [bos] + inst['context'] \n","  token_types = [context for _ in range(len(inst['context'])+1)]\n","  lm_labels = [-1 for _ in range(len(inst['context'])+1)]\n","  \n","  \n","  sequence.extend([question]+inst['question']+[eos])\n","  token_types.extend([question for _ in range(len(inst['question'])+2)])\n","  lm_labels.extend([question]+inst['question']+[eos])\n","  \n","  \n","  \n","  \n","  #instance[\"input_ids\"] = torch.tensor(sequence)\n","  #instance[\"token_type_ids\"] = torch.tensor(token_types)\n","  #instance[\"lm_labels\"] = torch.tensor(lm_labels)\n","  return torch.tensor(sequence),torch.tensor(token_types), torch.tensor(lm_labels)\n","  \n","\n","def pad_and_sort_batch(DataLoaderBatch):\n","  batch_size = len(DataLoaderBatch)\n","  batch_split = list(zip(*DataLoaderBatch))\n","  \n","  seqs,types,labels = batch_split[0],batch_split[1],batch_split[2]\n","  seqs = [seq.tolist() for seq in seqs]\n","  types = [typ.tolist() for typ in types] \n","  labels = [lb.tolist() for lb in labels]\n","  \n","  max_len = max([len(seq) for seq in seqs])\n","  \n","  \n","  seqs = [seq+[pad]*(max_len-len(seq)) for seq in seqs]\n","  types = [seq+[pad]*(max_len-len(seq)) for seq in types] \n","  labels = [seq+[pad]*(max_len-len(seq)) for seq in labels]\n","  \n","  return torch.tensor(seqs),torch.tensor(types),torch.tensor(labels)\n","  \n","  \n","\n","class MyDataset(Dataset):\n","  def __init__(self,path):\n","    \n","    self.path = path\n","    self.data_files = os.listdir(path)\n","\n","  def __getitem__(self, idx):\n","    with open(self.path+\"/\"+self.data_files[idx]) as f:\n","      txt = \" \".join(f.readlines())\n","    return get_example(txt)\n","\n","  def __len__(self):\n","      return len(self.data_files)\n","    \n","train_dataset = MyDataset(\"train_data\")\n","eval_dataset = MyDataset(\"eval_data\")\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=4,collate_fn = pad_and_sort_batch)\n","eval_loader =  DataLoader(eval_dataset, batch_size=2, shuffle=False, num_workers=4,collate_fn = pad_and_sort_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHTu-L0Ku2ZJ","colab_type":"code","outputId":"ae9d4e87-d77d-45e4-9f21-058f4dfdceaa","executionInfo":{"status":"error","timestamp":1573229075224,"user_tz":-330,"elapsed":251292,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}},"colab":{"base_uri":"https://localhost:8080/","height":446}},"source":["for step, (x, y,z) in tqdm_notebook(enumerate(train_loader)): \n","  if x.size()[1]>1024  or y.size()[1]>1024 or z.size()[1]>1024:\n","    print(tokenizer.decode(x[0].tolist()))\n","    print(step)\n","    break"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ac962e92ddb473abc46274b5028a027","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum  sequence length for this OpenAI GPT model (1053 > 1024). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum  sequence length for this OpenAI GPT model (1406 > 1024). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum  sequence length for this OpenAI GPT model (1116 > 1024). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-33faae5bfb7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1024\u001b[0m  \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1024\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;34m\"\"\"Backward-compatibility to use: for x in tqdm(iterable)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m         \u001b[0;31m# Inlining instance variables as locals (speed optimisation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m         \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mshared_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStorageWeakRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, storage_ref)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_dead_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vX5Iv6EEvsUf","colab_type":"code","outputId":"512285b8-73fb-47e4-c4c6-563b6e07985a","executionInfo":{"status":"ok","timestamp":1573261502826,"user_tz":-330,"elapsed":22738,"user":{"displayName":"Santhosh Kolloju","photoUrl":"","userId":"04379660425763606530"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["args = {'distributed':False,'train_batch_size':2,'valid_batch_size':2,\n","       \"device\":\"cuda\",\n","        \"model_checkpoint\":\"gpt2\",\n","        \"lr\":6.25e-5,\n","        \"local_rank\":-1,\n","        \"n_epochs\":15,\n","        \"max_norm\":1.0,\n","        \"gradient_accumulation_steps\":8,\n","        \"output_dir\":\"/content/drive/My Drive/harvest/\",\"fp16\":\"\"\n","        \n","       }\n","from collections import namedtuple\n","args = namedtuple(\"GenericDict\",args.keys())(**args)\n","#torch.cuda.empty()\n","model_class = GPT2LMHeadModel if \"gpt2\" in args.model_checkpoint else OpenAIGPTLMHeadModel\n","model = model_class.from_pretrained(\"/content/drive/My Drive/harvest/\")\n","tokenizer.set_special_tokens(SPECIAL_TOKENS)\n","model.set_num_special_tokens(len(SPECIAL_TOKENS))\n","model.to(args.device)\n","optimizer = OpenAIAdam(model.parameters(), lr=args.lr)\n","# Training function and trainer\n","def update(engine, batch):\n","    model.train()\n","    #batch = tuple(input_tensor.to(args.device) for input_tensor in batch)\n","    \n","    \n","    lm_loss = model(batch[0].to(args.device), token_type_ids=batch[1].to(args.device),\n","                    lm_labels=batch[2].to(args.device))\n","    loss = lm_loss / args.gradient_accumulation_steps\n","    if args.fp16:\n","        with amp.scale_loss(loss, optimizer) as scaled_loss:\n","            scaled_loss.backward()\n","        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_norm)\n","    else:\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_norm)\n","    if engine.state.iteration % args.gradient_accumulation_steps == 0:\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    return loss.item()\n","trainer = Engine(update)\n","# Evaluation function and evaluator (evaluator output is the input of the metrics)\n","def inference(engine, batch):\n","    model.eval()\n","    with torch.no_grad():\n","        #batch = tuple(input_tensor.to(args.device) for input_tensor in batch)\n","        #input_ids, lm_labels, token_type_ids = batch\n","        input_ids = batch[0].to(args.device)\n","        lm_labels = batch[1].to(args.device)\n","        token_type_ids = batch[2].to(args.device)\n","\n","        # logger.info(tokenizer.decode(input_ids[0, :].tolist()))\n","        model_outputs = model(input_ids, token_type_ids=token_type_ids)\n","        lm_logits = model_outputs[0]\n","\n","        lm_logits_flat_shifted = lm_logits[..., :-1, :].contiguous().view(-1, lm_logits.size(-1))\n","        lm_labels_flat_shifted = lm_labels[..., 1:].contiguous().view(-1)\n","\n","        return lm_logits_flat_shifted, lm_labels_flat_shifted\n","evaluator = Engine(inference)\n","trainer.add_event_handler(Events.EPOCH_COMPLETED, lambda _: evaluator.run(eval_loader))\n","if args.n_epochs < 1:\n","    trainer.add_event_handler(Events.COMPLETED, lambda _: evaluator.run(eval_loader))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["t_total value of -1 results in schedule not being applied\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rnzsBet2wKeP","colab_type":"code","outputId":"077320cc-8e75-4924-ccc7-fa47c9e60f54","colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["def average_distributed_scalar(scalar, args):\n","    \"\"\" Average a scalar over the nodes if we are in distributed training. We use this for distributed evaluation. \"\"\"\n","    if args.local_rank == -1:\n","        return scalar\n","    scalar_t = torch.tensor(scalar, dtype=torch.float, device=args.device) / torch.distributed.get_world_size()\n","    torch.distributed.all_reduce(scalar_t, op=torch.distributed.ReduceOp.SUM)\n","    return scalar_t.item()\n","  \n","# Linearly decrease the learning rate from lr to zero\n","scheduler = PiecewiseLinear(optimizer, \"lr\", [(0, args.lr), (args.n_epochs * len(train_loader), 0.0)])\n","trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n","\n","# Prepare metrics - note how we compute distributed metrics\n","RunningAverage(output_transform=lambda x: x).attach(trainer, \"loss\")\n","metrics = {\n","    \"nll\": Loss(torch.nn.CrossEntropyLoss(ignore_index=-1))\n","}\n","metrics.update({\n","    \"average_nll\": MetricsLambda(average_distributed_scalar, metrics[\"nll\"], args)\n","})\n","metrics[\"average_ppl\"] = MetricsLambda(math.exp, metrics[\"average_nll\"])\n","for name, metric in metrics.items():\n","    metric.attach(evaluator, name)\n","\n","# On the main process: add progress bar, tensorboard, checkpoints and save model, configuration and tokenizer before we start to train\n","if args.local_rank in [-1, 0]:\n","    pbar = ProgressBar(persist=True)\n","    pbar.attach(trainer, metric_names=[\"loss\"])\n","    evaluator.add_event_handler(Events.COMPLETED, lambda _: pbar.log_message(\"Validation: %s\" % pformat(evaluator.state.metrics)))\n","\n","    tb_logger = TensorboardLogger(log_dir=args.output_dir)\n","    tb_logger.attach(trainer, log_handler=OutputHandler(tag=\"training\", metric_names=[\"loss\"]), event_name=Events.ITERATION_COMPLETED)\n","    tb_logger.attach(trainer, log_handler=OptimizerParamsHandler(optimizer), event_name=Events.ITERATION_STARTED)\n","    tb_logger.attach(evaluator, log_handler=OutputHandler(tag=\"validation\", metric_names=list(metrics.keys()), another_engine=trainer), event_name=Events.EPOCH_COMPLETED)\n","\n","    checkpoint_handler = ModelCheckpoint(\"/content/drive/My Drive/harvest/\", 'checkpoint', save_interval=10000, n_saved=5)\n","    trainer.add_event_handler(Events.ITERATION_COMPLETED, checkpoint_handler, {'mymodel': getattr(model, 'module', model)})  # \"getattr\" take care of distributed encapsulation\n","\n","    #torch.save(args, tb_logger.writer.log_dir + '/model_training_args.bin')\n","    getattr(model, 'module', model).config.to_json_file(os.path.join(tb_logger.writer.log_dir, CONFIG_NAME))\n","    tokenizer.save_vocabulary(tb_logger.writer.log_dir)\n","\n","# Run the training\n","trainer.run(train_loader, max_epochs=args.n_epochs)\n","\n","# On the main process: close tensorboard logger and rename the last checkpoint (for easy re-loading with OpenAIGPTModel.from_pretrained method)\n","if args.local_rank in [-1, 0] and args.n_epochs > 0:\n","    os.rename(checkpoint_handler._saved[-1][1][-1], os.path.join(tb_logger.writer.log_dir, WEIGHTS_NAME))  # TODO: PR in ignite to have better access to saved file paths (cleaner)\n","    tb_logger.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Buffered data was truncated after reaching the output size limit.Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p4CiL8n3w0hW","colab_type":"code","colab":{}},"source":["!rm -r logs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2kCrKZ_xVWq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}